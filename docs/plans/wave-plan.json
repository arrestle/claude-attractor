{"generated_at": "2026-02-23T07:44:58Z", "total_gaps": 56, "waves": [{"wave": 1, "theme": "Structural Wiring \u2014 Foundation Fixes", "estimated_effort": "1 day", "depends_on": [], "items": [{"module": "attractor_agent", "checklist_item": "Root Cause A \u2014 Wire _shell() to process tracking callback so SIGTERM/SIGKILL abort logic is reachable (\u00a79.1.6, \u00a79.11.5)", "verdict": "PARTIAL", "priority": "P1", "description": "In tools/core.py _shell(), after the subprocess is spawned, call get_process_callback() and invoke it with the proc object so Session._tracked_processes is populated. Requires LocalEnvironment.exec_shell() to expose the subprocess object before proc.wait() is called (e.g. via env.last_process or an on_spawn callback). Once wired, the SIGTERM/SIGKILL shutdown sequence already fully implemented at session.py:769\u2013841 becomes reachable on abort. Without this fix, \u00a79.1.6 and \u00a79.11.5 are dead-code-complete: the kill logic exists but nothing feeds it.", "affected_files": ["src/attractor_agent/tools/core.py", "src/attractor_agent/session.py"]}, {"module": "attractor_agent", "checklist_item": "Root Cause B \u2014 Pass profile.supports_parallel_tool_calls to ToolRegistry constructor (\u00a79.3.5)", "verdict": "PARTIAL", "priority": "P1", "description": "In session.py:236\u2013240, add supports_parallel_tool_calls=self._profile.supports_parallel_tool_calls to the ToolRegistry(...) constructor call. The parameter already exists on ToolRegistry (registry.py:96) and is used internally (line 243); it is simply never populated from the profile. All three current profiles return True so the default produces accidentally correct behavior, but any profile returning False is silently ignored. This one-line change makes the wiring explicit and safe.", "affected_files": ["src/attractor_agent/session.py", "src/attractor_agent/tools/registry.py"]}, {"module": "attractor_agent", "checklist_item": "SESSION_END not emitted on normal submit() completion without explicit close() (\u00a79.10.4)", "verdict": "PARTIAL", "priority": "P1", "description": "In session.py:454 finally block, the else-branch (normal completion, no abort, no auth error) transitions to IDLE and emits TURN_END but never emits SESSION_END. Callers using the session without a context manager (no async with, no explicit close()) receive TURN_END but no SESSION_END on the happy path. Fix: emit SESSION_END in the else branch when the agent loop terminates naturally (loop iteration count reached or LLM returns no tool calls), or add an unconditional SESSION_END emission to a _run_loop() finally clause invoked only when the loop exits cleanly.", "affected_files": ["src/attractor_agent/session.py"]}]}, {"wave": 2, "theme": "Core Behavior Fixes \u2014 Published Interfaces vs. Actual Behavior", "estimated_effort": "1\u20132 days", "depends_on": [1], "items": [{"module": "attractor_llm", "checklist_item": "Middleware chain silently discarded \u2014 Client(middleware=[...]) is a no-op (\u00a78.1.6)", "verdict": "PARTIAL", "priority": "P1", "description": "Client.__init__ accepts middleware=, emits a DeprecationWarning, and stores the list in self._middleware, but neither complete() nor stream() reference self._middleware at any point. Define a proper Middleware Protocol replacing the Middleware = Any alias at line 24 (e.g. a callable (Request, Callable[[Request], Response]) -> Response). Then wrap the _do_complete callable in complete() and the adapter.stream() call in stream() through the stored middleware list in registration order. The warning infrastructure is already tested; only the application logic is absent.", "affected_files": ["src/attractor_llm/client.py"]}, {"module": "attractor_agent", "checklist_item": "Anthropic profile silently overwrites caller-supplied tool descriptions for edit_file and write_file (\u00a79.2.6)", "verdict": "PARTIAL", "priority": "P2", "description": "In profiles/anthropic.py:49, _ANTHROPIC_TOOL_DESCRIPTIONS.get(tool.name, tool.description) unconditionally overwrites the description for any tool named edit_file or write_file regardless of what the caller provided. The execute handler is preserved. Resolution options: (a) only apply the override when tool.description is None or empty, treating non-empty caller descriptions as intentional; (b) add an opt-in override flag to the Tool dataclass; (c) document the override as intentional and let callers rename their tools to avoid collision. Whichever option is chosen, add a test asserting the chosen behavior when a caller-supplied description for a known name is present.", "affected_files": ["src/attractor_agent/profiles/anthropic.py", "tests/test_profiles.py"]}, {"module": "attractor_pipeline", "checklist_item": "R13 validation rule accepts label as substitute for prompt \u2014 diverges from spec (\u00a711.2.7)", "verdict": "PARTIAL", "priority": "P2", "description": "In validation.py:353, the R13 condition is `not node.prompt and not node.label`, which suppresses the WARNING when label is present but prompt is absent. The spec mandates a WARNING whenever prompt is absent on a box node, unconditionally. Fix: change condition to `not node.prompt` so that box nodes with only a label still trigger the warning. Update test_wave1_spec_compliance.py:567 (test_box_node_with_label_no_warning) to assert a WARNING is produced for the label-but-no-prompt case instead of expecting silence.", "affected_files": ["src/attractor_pipeline/validation.py", "tests/test_wave1_spec_compliance.py"]}, {"module": "attractor_pipeline", "checklist_item": "Interviewer Protocol ask() returns str instead of spec-required Answer (\u00a711.8.1)", "verdict": "PARTIAL", "priority": "P2", "description": "The Interviewer Protocol's ask() method returns str (human.py:117). The DoD requires ask(question) -> Answer. The existing ask_question_via_ask() module-level bridge converts str -> Answer but is not part of the Protocol contract. Fix option A (spec-compliant): change ask() -> str to ask() -> Answer in the Protocol definition, update all concrete implementations (ConsoleInterviewer, TestInterviewer, etc.), and remove the bridge helper. Fix option B (intentional divergence): update the spec to accept the flat str API and formalize that ask_question_via_ask() is the canonical bridge. Choose one and update tests in test_audit4_gaps.py:517 accordingly.", "affected_files": ["src/attractor_pipeline/handlers/human.py", "tests/test_audit4_gaps.py"]}, {"module": "attractor_pipeline", "checklist_item": "HTTP server POST /run dispatches asyncio.sleep(0) stub \u2014 real pipeline runner never called (\u00a711.11.5)", "verdict": "PARTIAL", "priority": "P1", "description": "In server/app.py:57, _execute_pipeline() body is await asyncio.sleep(0) with a comment pointing to PipelineRunner. The async task dispatch (asyncio.create_task), 202 Accepted response, cancellation handling, and pending\u2192running\u2192completed/failed/cancelled state machine are all correct. Only the execution body needs replacing: import PipelineRunner from attractor_pipeline.engine.runner and substitute await PipelineRunner(graph=run['pipeline']).run(run['input']). Note: attractor_server/app.py is the real production server and is already wired; this fixes only the attractor_pipeline/server stub used in pipeline-mode deployments.", "affected_files": ["src/attractor_pipeline/server/app.py"]}]}, {"wave": 3, "theme": "Critical Live Integration Test Coverage \u2014 Core Agent Scenarios", "estimated_effort": "1\u20132 days", "depends_on": [1, 2], "items": [{"module": "attractor_agent", "checklist_item": "Live file creation tests for OpenAI and Gemini providers \u2014 Anthropic already covered (\u00a79.12.1, \u00a79.12.2, \u00a79.12.3)", "verdict": "PARTIAL", "priority": "P1", "description": "test_e2e_integration.py:79 covers Anthropic (\u00a79.12.2). Add equivalent TestAgentWithRealTools tests for OpenAI (\u00a79.12.1, requires OPENAI_API_KEY) and Gemini (\u00a79.12.3, requires GEMINI_API_KEY). Each test must exercise the full path: Session.submit() \u2192 live LLM \u2192 write_file tool call \u2192 verify file exists on disk with correct content. Guard with @skip_no_openai and @skip_no_gemini markers. Model structure on test_agent_writes_and_reads_file.", "affected_files": ["tests/test_e2e_integration.py"]}, {"module": "attractor_agent", "checklist_item": "Live read+edit tests for OpenAI and Gemini providers \u2014 Anthropic already covered (\u00a79.12.4, \u00a79.12.5, \u00a79.12.6)", "verdict": "PARTIAL", "priority": "P1", "description": "test_e2e_integration.py:111 covers Anthropic (\u00a79.12.5). Add OpenAI (\u00a79.12.4) and Gemini (\u00a79.12.6) equivalents that exercise: pre-seed a temp file with known content, submit a prompt directing the agent to modify a specific value, verify the edit is correct on disk. Use @skip_no_openai and @skip_no_gemini markers. Model on test_agent_edits_existing_file.", "affected_files": ["tests/test_e2e_integration.py"]}, {"module": "attractor_agent", "checklist_item": "Live shell execution and shell timeout tests \u2014 all three providers \u2014 unblocked by Wave 1 Root Cause A (\u00a79.12.10\u201315)", "verdict": "PARTIAL", "priority": "P1", "description": "Depends on Wave 1 Root Cause A (_shell() process callback wiring) before timeout scenarios are reachable. Add two test classes per provider: (a) simple shell execution \u2014 prompt the agent to run a benign command (e.g. echo or pwd) and verify the output appears in the tool result; (b) shell timeout with abort \u2014 fire AbortSignal during a long-running shell command and verify SIGTERM is sent within the timeout window and the session transitions to CLOSED. Cover OpenAI (\u00a79.12.10, \u00a79.12.13), Anthropic (\u00a79.12.11, \u00a79.12.14), and Gemini (\u00a79.12.12, \u00a79.12.15) with respective skip markers.", "affected_files": ["tests/test_e2e_integration.py", "src/attractor_agent/tools/core.py"]}, {"module": "attractor_agent", "checklist_item": "Live parallel tool call tests \u2014 all three providers \u2014 unblocked by Wave 1 Root Cause B (\u00a79.12.25\u201327)", "verdict": "PARTIAL", "priority": "P1", "description": "Depends on Wave 1 Root Cause B (supports_parallel_tool_calls wiring) to be structurally meaningful. Add live tests that issue a prompt requiring two simultaneous read_file calls (e.g. 'compare fileA and fileB') and assert both tool results are returned in a single turn for providers where supports_parallel_tool_calls=True. Also add a unit test with a mock profile returning supports_parallel_tool_calls=False and verify ToolRegistry.supports_parallel_tool_calls propagates correctly (not just defaults). Cover OpenAI (\u00a79.12.25), Anthropic (\u00a79.12.26), Gemini (\u00a79.12.27).", "affected_files": ["tests/test_e2e_integration.py", "src/attractor_agent/session.py"]}, {"module": "attractor_llm", "checklist_item": "Cache efficiency >50% threshold assertions for OpenAI and Gemini \u2014 Anthropic already asserts the threshold (\u00a78.6.9)", "verdict": "PARTIAL", "priority": "P2", "description": "test_audit2_wave5_pipeline_hardening.py contains three live xfail tests. TestAnthropicCacheEfficiency at line 294 already asserts cache_read / input_tokens > 0.50 across 5 turns \u2014 matching the DoD. TestOpenAICacheEfficiency (line 260) and TestGeminiCacheEfficiency (line 362) only assert cumulative_cache_reads > 0. Upgrade both to assert the >50% threshold by turn 5 to match the Anthropic test. Retain @pytest.mark.xfail(strict=False) since provider-side caching is non-deterministic. Also verify the mock-based threshold test in test_wave16a_mock_coverage.py:113 still passes after any refactoring.", "affected_files": ["tests/test_audit2_wave5_pipeline_hardening.py", "tests/test_wave16a_mock_coverage.py"]}, {"module": "attractor_agent", "checklist_item": "Live subagent spawn tests for OpenAI and Gemini \u2014 Anthropic already covered (\u00a79.12.34, \u00a79.12.35, \u00a79.12.36)", "verdict": "PARTIAL", "priority": "P2", "description": "test_e2e_integration.py:315 and :336 cover Anthropic subagent spawn with and without tools (\u00a79.12.35). Add OpenAI (\u00a79.12.34) and Gemini (\u00a79.12.36) equivalents in a new TestSubagentReal subclass or parametrize the existing class. Each test must exercise spawn_subagent() \u2192 live LLM \u2192 text output (without tools) and spawn_subagent(include_tools=True) \u2192 live LLM \u2192 write_file \u2192 verify file on disk. Use @skip_no_openai and @skip_no_gemini markers.", "affected_files": ["tests/test_e2e_integration.py"]}]}, {"wave": 4, "theme": "Comprehensive Live Test Parity \u2014 Remaining \u00a79.12 Scenarios", "estimated_effort": "2 days", "depends_on": [1, 2, 3], "items": [{"module": "attractor_agent", "checklist_item": "Live multi-file edit tests \u2014 all three providers (\u00a79.12.7, \u00a79.12.8, \u00a79.12.9)", "verdict": "PARTIAL", "priority": "P2", "description": "Add live tests where the agent is prompted to make coordinated edits across two or more files in a single session (e.g. rename a constant defined in fileA and referenced in fileB). The test must verify both files are updated correctly on disk. Cover OpenAI, Anthropic, and Gemini with respective skip markers. Note: the existing pipeline test in test_e2e_integration.py:151 uses DirectLLMBackend and does not exercise the multi-file edit path.", "affected_files": ["tests/test_e2e_integration.py"]}, {"module": "attractor_agent", "checklist_item": "Live grep and glob search tests \u2014 all three providers (\u00a79.12.16, \u00a79.12.17, \u00a79.12.18)", "verdict": "PARTIAL", "priority": "P2", "description": "Add live tests that seed a temp directory tree with known files, then prompt the agent to locate content using grep (pattern search) and glob (file discovery). Verify the agent's tool results contain the expected filenames and matched lines, and that line/output truncation limits do not silently swallow relevant results. Cover OpenAI, Anthropic, and Gemini.", "affected_files": ["tests/test_e2e_integration.py"]}, {"module": "attractor_agent", "checklist_item": "Live multi-step read \u2192 analyze \u2192 edit task tests \u2014 all three providers (\u00a79.12.19, \u00a79.12.20, \u00a79.12.21)", "verdict": "PARTIAL", "priority": "P2", "description": "Add live tests that require a chain of dependent tool calls within a single turn: read a file to retrieve content, reason about it (e.g. identify a bug or extract a value), then make a targeted edit based on that reasoning. These validate the agent loop's ability to use the result of one tool call as context for the next without user prompting. Cover all three providers.", "affected_files": ["tests/test_e2e_integration.py"]}, {"module": "attractor_agent", "checklist_item": "Live tool output truncation tests \u2014 all three providers (\u00a79.12.22, \u00a79.12.23, \u00a79.12.24)", "verdict": "PARTIAL", "priority": "P2", "description": "Add live tests that produce tool output exceeding the configured tool_output_limits (e.g. read a file with 10,000 lines against a 500-line limit). Verify: (a) the agent receives the truncated version without an exception; (b) the agent continues the loop correctly despite truncation; (c) the truncation marker or note is visible in the tool result. Cover OpenAI, Anthropic, and Gemini with respective skip markers.", "affected_files": ["tests/test_e2e_integration.py"]}, {"module": "attractor_agent", "checklist_item": "Live steering mid-task tests \u2014 all three providers (\u00a79.12.28, \u00a79.12.29, \u00a79.12.30)", "verdict": "PARTIAL", "priority": "P2", "description": "Add live tests that inject a second submit() call while the agent loop is mid-execution (between tool calls) to redirect its goal. Verify the agent incorporates the steering message and adjusts its subsequent actions accordingly \u2014 not ignoring it or treating it as an error. Use asyncio.create_task to interleave the steering submit with an in-progress session. Cover OpenAI, Anthropic, and Gemini.", "affected_files": ["tests/test_e2e_integration.py"]}, {"module": "attractor_agent", "checklist_item": "Live reasoning effort change tests \u2014 all three providers (\u00a79.12.31, \u00a79.12.32, \u00a79.12.33)", "verdict": "PARTIAL", "priority": "P2", "description": "Add live tests that change the reasoning_effort setting between turns (e.g. low on turn 1, high on turn 2) and verify the updated value is propagated to the LLM request on the next call. For OpenAI this maps to the o-series thinking budget; for Anthropic to extended thinking tokens; for Gemini to thinking_config. The test should inspect the outgoing request or a TURN_START event to confirm the effort level is applied. Cover all three providers.", "affected_files": ["tests/test_e2e_integration.py"]}, {"module": "attractor_agent", "checklist_item": "Live loop detection tests \u2014 all three providers (\u00a79.12.37, \u00a79.12.38, \u00a79.12.39)", "verdict": "PARTIAL", "priority": "P2", "description": "Add live tests that craft a prompt designed to induce repetitive identical tool calls (e.g. the LLM repeatedly calls read_file on the same path without making progress). Verify the agent raises a LoopDetectedError (or equivalent) and terminates rather than spinning indefinitely. Tests can use mock adapters that return scripted repetitive tool call sequences combined with the live session infrastructure, or can rely on provider-specific prompts known to trigger loops. Cover all three providers.", "affected_files": ["tests/test_e2e_integration.py"]}, {"module": "attractor_agent", "checklist_item": "Live error recovery tests \u2014 all three providers (\u00a79.12.40, \u00a79.12.41, \u00a79.12.42)", "verdict": "PARTIAL", "priority": "P2", "description": "Add live tests where a registered tool raises an exception mid-loop (e.g. a tool that deliberately throws ValueError on first call). Verify the agent either: (a) retries the operation; (b) reports the error to the LLM as a structured tool result and continues; or (c) surfaces it as a typed error to the caller. The session must not leak an unhandled exception or deadlock. Cover OpenAI, Anthropic, and Gemini with respective skip markers.", "affected_files": ["tests/test_e2e_integration.py"]}, {"module": "attractor_agent", "checklist_item": "Live provider-specific editing format validation tests \u2014 all three providers (\u00a79.12.43, \u00a79.12.44, \u00a79.12.45)", "verdict": "PARTIAL", "priority": "P2", "description": "Verify that each provider's profile produces correctly formatted tool schemas in live calls. Currently only mock-covered for Anthropic (test_profiles.py:308). Add live tests that register edit_file and write_file tools, submit a prompt that triggers their use, and assert the correct tool schema was transmitted (Anthropic: canned description override applied; OpenAI: function-calling JSON schema format; Gemini: FunctionDeclaration format). Capture the outgoing request via a spy or event hook. Cover all three providers.", "affected_files": ["tests/test_e2e_integration.py", "tests/test_profiles.py"]}]}]}
